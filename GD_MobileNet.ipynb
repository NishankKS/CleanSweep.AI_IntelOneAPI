{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d786e09e-63f9-482d-ab48-4484b997d1b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-18 08:06:04.084943: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-18 08:06:04.218798: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /glob/development-tools/versions/oneapi/2023.0.1/oneapi/vpl/2023.0.0/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/tbb/2021.8.0/env/../lib/intel64/gcc4.8:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/rkcommon/1.10.0/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/ospray_studio/0.11.1/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/ospray/2.10.0/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/openvkl/1.3.1/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/oidn/1.4.3/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/mpi/2021.8.0//libfabric/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/mpi/2021.8.0//lib/release:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/mpi/2021.8.0//lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/mkl/2023.0.0/lib/intel64:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/itac/2021.8.0/slib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/ispc/1.18.1/lib/lib64:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/ipp/2021.7.0/lib/intel64:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/ippcp/2021.6.3/lib/intel64:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/ipp/2021.7.0/lib/intel64:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/embree/3.13.5/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/dnnl/2023.0.0/cpu_dpcpp_gpu_dpcpp/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/debugger/2023.0.0/gdb/intel64/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/debugger/2023.0.0/libipt/intel64/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/debugger/2023.0.0/dep/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/dal/2023.0.0/lib/intel64:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/compiler/2023.0.0/linux/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/compiler/2023.0.0/linux/lib/x64:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/compiler/2023.0.0/linux/lib/oclfpga/host/linux64/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/compiler/2023.0.0/linux/compiler/lib/intel64_lin:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/ccl/2021.8.0/lib/cpu_gpu_dpcpp\n",
      "2023-03-18 08:06:04.218843: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-03-18 08:06:07.639828: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /glob/development-tools/versions/oneapi/2023.0.1/oneapi/vpl/2023.0.0/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/tbb/2021.8.0/env/../lib/intel64/gcc4.8:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/rkcommon/1.10.0/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/ospray_studio/0.11.1/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/ospray/2.10.0/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/openvkl/1.3.1/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/oidn/1.4.3/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/mpi/2021.8.0//libfabric/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/mpi/2021.8.0//lib/release:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/mpi/2021.8.0//lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/mkl/2023.0.0/lib/intel64:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/itac/2021.8.0/slib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/ispc/1.18.1/lib/lib64:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/ipp/2021.7.0/lib/intel64:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/ippcp/2021.6.3/lib/intel64:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/ipp/2021.7.0/lib/intel64:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/embree/3.13.5/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/dnnl/2023.0.0/cpu_dpcpp_gpu_dpcpp/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/debugger/2023.0.0/gdb/intel64/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/debugger/2023.0.0/libipt/intel64/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/debugger/2023.0.0/dep/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/dal/2023.0.0/lib/intel64:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/compiler/2023.0.0/linux/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/compiler/2023.0.0/linux/lib/x64:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/compiler/2023.0.0/linux/lib/oclfpga/host/linux64/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/compiler/2023.0.0/linux/compiler/lib/intel64_lin:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/ccl/2021.8.0/lib/cpu_gpu_dpcpp\n",
      "2023-03-18 08:06:07.640394: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /glob/development-tools/versions/oneapi/2023.0.1/oneapi/vpl/2023.0.0/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/tbb/2021.8.0/env/../lib/intel64/gcc4.8:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/rkcommon/1.10.0/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/ospray_studio/0.11.1/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/ospray/2.10.0/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/openvkl/1.3.1/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/oidn/1.4.3/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/mpi/2021.8.0//libfabric/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/mpi/2021.8.0//lib/release:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/mpi/2021.8.0//lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/mkl/2023.0.0/lib/intel64:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/itac/2021.8.0/slib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/ispc/1.18.1/lib/lib64:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/ipp/2021.7.0/lib/intel64:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/ippcp/2021.6.3/lib/intel64:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/ipp/2021.7.0/lib/intel64:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/embree/3.13.5/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/dnnl/2023.0.0/cpu_dpcpp_gpu_dpcpp/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/debugger/2023.0.0/gdb/intel64/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/debugger/2023.0.0/libipt/intel64/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/debugger/2023.0.0/dep/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/dal/2023.0.0/lib/intel64:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/compiler/2023.0.0/linux/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/compiler/2023.0.0/linux/lib/x64:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/compiler/2023.0.0/linux/lib/oclfpga/host/linux64/lib:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/compiler/2023.0.0/linux/compiler/lib/intel64_lin:/glob/development-tools/versions/oneapi/2023.0.1/oneapi/ccl/2021.8.0/lib/cpu_gpu_dpcpp\n",
      "2023-03-18 08:06:07.640427: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2,geocoder\n",
    "import time\n",
    "import datetime\n",
    "from twilio.rest import Client\n",
    "import yagmail\n",
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "56fab04f-f863-43bd-a2ef-3ccc26ab13ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call(lat,lon):\n",
    "  auth=\"ENTER_YOUR_TWILIO_AUTH_PASS\"\n",
    "  account_sid = 'ENTER_YOUR_TWILIO_AUTH_ID'\n",
    "  client = Client(account_sid, auth)\n",
    "  call = client.calls.create(twiml=\"<Response><Gather action=\\\"/gather_results\\\" digits=\\\"1\\\"><Say>Attention Required!! Garbage Detected... Garbage Detected... Garbage detected</Say></Gather></Response>\",\n",
    "    from_='+YOUR_PHONE_NUMBER',\n",
    "    to='+RECEIVER_PHONE_NUMBER'\n",
    "  )\n",
    "  print(call.sid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "66c73261-5a9e-4221-bf91-b8dbb7dd69a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sms(t1,lat,lon):\n",
    "  auth = \"ENTER_YOUR_TWILIO_AUTH_PASS\"\n",
    "  sid = 'ENTER_YOUR_TWILIO_AUTH_ID'\n",
    "  geolocator = Nominatim(user_agent=\"geoapiExercises\")\n",
    "  location = geolocator.reverse(str(lat) + \",\" +str(lon))\n",
    "  address = location.raw['address']\n",
    "  google_maps_link = f\"https://www.google.com/maps/search/?api=1&query={float(lat)},{float(lon)}\"\n",
    "  address = list(address.values())\n",
    "  address = \",\".join(address)\n",
    "  case = \"Attention Required!!\"\n",
    "  cl = Client(sid, auth)\n",
    "  cl.messages.create(body=f\"{case}\\nScrap detected Time: {t1}\\nLocation: {google_maps_link}\\nAddress: {address}\", from_ = '+YOUR_PHONE_NUMBER', to = '+RECEIVER_PHONE_NUMBER')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "06e51fd2-85f0-4ed5-b880-699a5c5dad38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def email_generate(t1, lattitude, longitude):\n",
    "  app_pass = \"ENTER_YOUR_GMAIL_PASSWORD\"\n",
    "  geolocator = Nominatim(user_agent=\"MyApp\")\n",
    "  #tval = t2 - t1\n",
    "  Longitude = longitude\n",
    "  Lattitude = lattitude\n",
    "  location = geolocator.reverse(str(lattitude) + \",\" + str(Longitude))\n",
    "  address = location.raw['address']\n",
    "  google_maps_link = f\"https://www.google.com/maps/search/?api=1&query={float(Lattitude)},{float(Longitude)}\"\n",
    "  from_address = \"mgakhil04@gmail.com\"#Provide your mail id\n",
    "  to_address = \"mgakhil03@gmail.com\"#Provide receiver mail id\n",
    "  subject = \"Test Email\"\n",
    "  case = \"Attention Required!!\"\n",
    "  address = list(address.values())\n",
    "  address = \",\".join(address)\n",
    "  html = f\"<h1>{case}</h1> <h2> Address: </h2><h3>{address}</h3><h3><a href={google_maps_link}>Location on GoogleMaps</a></h3><h2>Scrap detected Time:</h2><h3>{t1}</h3>\"\n",
    "  # Connect to your Gmail account and send the email\n",
    "  yag = yagmail.SMTP(from_address,app_pass)\n",
    "  contents=[html,yagmail.inline(\"./kill.jpg\")]\n",
    "  yag.send(to=to_address, subject=subject, contents=contents)\n",
    "  print(\"Done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4db19ee9-6202-4225-8727-50fa21ad8858",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_graph(model_file):\n",
    "  graph = tf.Graph()\n",
    "  graph_def = tf.compat.v1.GraphDef()\n",
    "  with open(model_file, \"rb\") as f:\n",
    "    graph_def.ParseFromString(f.read())\n",
    "  with graph.as_default():\n",
    "    tf.import_graph_def(graph_def)\n",
    "  return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "997f8eae-b9f6-4159-af97-9c8520c49c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_tensor_from_image_file(file_name, input_height=299, input_width=299,input_mean=0, input_std=255):\n",
    "  input_name = \"file_reader\"\n",
    "  output_name = \"normalized\"\n",
    "  file_reader = tf.io.read_file(file_name, input_name)\n",
    "  if file_name.endswith(\".png\"):\n",
    "    image_reader = tf.image.decode_png(file_reader, channels = 3,name='png_reader')\n",
    "  elif file_name.endswith(\".gif\"):\n",
    "    image_reader = tf.squeeze(tf.image.decode_gif(file_reader,name='gif_reader'))\n",
    "  elif file_name.endswith(\".bmp\"):\n",
    "    image_reader = tf.image.decode_bmp(file_reader, name='bmp_reader')\n",
    "  else:\n",
    "    image_reader = tf.image.decode_jpeg(file_reader, channels = 3,name='jpeg_reader')\n",
    "  float_caster = tf.cast(image_reader, tf.float32)\n",
    "  dims_expander = tf.expand_dims(float_caster, 0);\n",
    "  resized = tf.compat.v1.image.resize_bilinear(dims_expander, [input_height, input_width])\n",
    "  normalized = tf.divide(tf.subtract(resized, [input_mean]), [input_std])\n",
    "  sess = tf.compat.v1.Session()\n",
    "  result = sess.run(normalized)\n",
    "  return result\n",
    "\n",
    "\n",
    "def load_labels(label_file):\n",
    "  label = []\n",
    "  proto_as_ascii_lines = tf.compat.v1.gfile.GFile(label_file).readlines()\n",
    "  for l in proto_as_ascii_lines:\n",
    "    label.append(l.rstrip())\n",
    "  return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bb8e0206-df43-495b-9f39-83469b447f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = \"files/retrained_graph.pb\"\n",
    "label_file = \"files/retrained_labels.txt\"\n",
    "input_height = 224\n",
    "input_width = 224\n",
    "input_mean = 128\n",
    "input_std = 128\n",
    "input_layer = \"input\"\n",
    "output_layer = \"final_result\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ebb587ef-cb39-4676-9ec6-afbe5150b72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(path):\n",
    "  print(\"Running Model\")\n",
    "  graph = load_graph(model_file)\n",
    "  \n",
    "  video_reader = cv2.VideoCapture(path)\n",
    "  li=[]\n",
    "\n",
    "  try:\n",
    "    c=2\n",
    "    while True:\n",
    "      ret, image_1 = video_reader.read()\n",
    "      cv2.imwrite(\"kill1\" + \".jpg\", image_1)\n",
    "      if c>1:\n",
    "        cv2.imwrite(\"kill\"+\".jpg\", image_1)\n",
    "        c-=1\n",
    "      file_name=\"kill1.jpg\"\n",
    "      for k in range(15):\n",
    "       video_reader.grab()\n",
    "      t = read_tensor_from_image_file(file_name,\n",
    "                                      input_height=input_height,\n",
    "                                      input_width=input_width,\n",
    "                                      input_mean=input_mean,\n",
    "                                      input_std=input_std)\n",
    "\n",
    "      input_name = \"import/\" + input_layer\n",
    "      output_name = \"import/\" + output_layer\n",
    "      input_operation = graph.get_operation_by_name(input_name)\n",
    "      output_operation = graph.get_operation_by_name(output_name)\n",
    "\n",
    "      with tf.compat.v1.Session(graph=graph) as sess:\n",
    "        start = time.time()\n",
    "        results = sess.run(output_operation.outputs[0],\n",
    "                          {input_operation.outputs[0]: t})\n",
    "        end=time.time()\n",
    "      results = np.squeeze(results)\n",
    "\n",
    "      top_k = results.argsort()[-5:][::-1]\n",
    "      labels = load_labels(label_file)\n",
    "      #print(labels)\n",
    "      print('\\nEvaluation time (1-image): {:.3f}s\\n'.format(end-start))\n",
    "      template = \"{} (score={:0.5f})\"\n",
    "      for i in top_k:\n",
    "        print(template.format(labels[i], results[i]))\n",
    "        if labels[i]==\"not clean\":\n",
    "          li.append(results[i])\n",
    "  except:\n",
    "    pass\n",
    "  print(\"Percentage that is not clean \"+str(sum(li)*100/len(li)))\n",
    "  density = sum(li)/len(li)\n",
    "  g= geocoder.ip('me')\n",
    "  lat, lon = g.latlng\n",
    "  k=[lat,lon]\n",
    "  geolocator = Nominatim(user_agent=\"geoapiExercises\")\n",
    "  location = geolocator.reverse(str(lat) + \",\" + str(lon))\n",
    "  address = location.raw['address']\n",
    "  address = list(address.values())\n",
    "  address = \",\".join(address)\n",
    "  with open('emer.txt', 'w') as file:\n",
    "    file.write(address)\n",
    "  ct = datetime.datetime.now()\n",
    "  end = time.time()\n",
    "  print(\"Time Taken: \",end-start)\n",
    "  \n",
    "  if 0.80<density<0.96 :\n",
    "    sms(ct,lat,lon)\n",
    "  elif 0.96<density<0.98:\n",
    "    whatsapp1(lat,lon)\n",
    "  elif density>0.98:\n",
    "    email_generate(ct,lat,lon)\n",
    "  else:\n",
    "   return \"No Garbage Detected\"\n",
    "  return \"Garbage Detected\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fec7ec37-63af-4373-b155-a81a20387b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Model\n",
      "\n",
      "Evaluation time (1-image): 0.137s\n",
      "\n",
      "not clean (score=1.00000)\n",
      "clean (score=0.00000)\n",
      "\n",
      "Evaluation time (1-image): 0.148s\n",
      "\n",
      "not clean (score=1.00000)\n",
      "clean (score=0.00000)\n",
      "\n",
      "Evaluation time (1-image): 0.146s\n",
      "\n",
      "not clean (score=1.00000)\n",
      "clean (score=0.00000)\n",
      "\n",
      "Evaluation time (1-image): 0.134s\n",
      "\n",
      "not clean (score=1.00000)\n",
      "clean (score=0.00000)\n",
      "\n",
      "Evaluation time (1-image): 0.138s\n",
      "\n",
      "not clean (score=0.99994)\n",
      "clean (score=0.00006)\n",
      "\n",
      "Evaluation time (1-image): 0.133s\n",
      "\n",
      "not clean (score=1.00000)\n",
      "clean (score=0.00000)\n",
      "\n",
      "Evaluation time (1-image): 0.142s\n",
      "\n",
      "not clean (score=1.00000)\n",
      "clean (score=0.00000)\n",
      "\n",
      "Evaluation time (1-image): 0.142s\n",
      "\n",
      "not clean (score=0.99973)\n",
      "clean (score=0.00027)\n",
      "\n",
      "Evaluation time (1-image): 0.131s\n",
      "\n",
      "not clean (score=0.99994)\n",
      "clean (score=0.00006)\n",
      "\n",
      "Evaluation time (1-image): 0.144s\n",
      "\n",
      "not clean (score=0.99139)\n",
      "clean (score=0.00861)\n",
      "\n",
      "Evaluation time (1-image): 0.134s\n",
      "\n",
      "not clean (score=1.00000)\n",
      "clean (score=0.00000)\n",
      "\n",
      "Evaluation time (1-image): 0.145s\n",
      "\n",
      "not clean (score=0.99982)\n",
      "clean (score=0.00018)\n",
      "\n",
      "Evaluation time (1-image): 0.134s\n",
      "\n",
      "not clean (score=0.99998)\n",
      "clean (score=0.00002)\n",
      "\n",
      "Evaluation time (1-image): 0.152s\n",
      "\n",
      "not clean (score=0.99999)\n",
      "clean (score=0.00000)\n",
      "\n",
      "Evaluation time (1-image): 0.133s\n",
      "\n",
      "not clean (score=1.00000)\n",
      "clean (score=0.00000)\n",
      "\n",
      "Evaluation time (1-image): 0.134s\n",
      "\n",
      "not clean (score=1.00000)\n",
      "clean (score=0.00000)\n",
      "\n",
      "Evaluation time (1-image): 0.132s\n",
      "\n",
      "not clean (score=1.00000)\n",
      "clean (score=0.00000)\n",
      "\n",
      "Evaluation time (1-image): 0.143s\n",
      "\n",
      "not clean (score=1.00000)\n",
      "clean (score=0.00000)\n",
      "\n",
      "Evaluation time (1-image): 0.135s\n",
      "\n",
      "not clean (score=1.00000)\n",
      "clean (score=0.00000)\n",
      "\n",
      "Evaluation time (1-image): 0.133s\n",
      "\n",
      "not clean (score=1.00000)\n",
      "clean (score=0.00000)\n",
      "\n",
      "Evaluation time (1-image): 0.132s\n",
      "\n",
      "not clean (score=1.00000)\n",
      "clean (score=0.00000)\n",
      "\n",
      "Evaluation time (1-image): 0.132s\n",
      "\n",
      "not clean (score=1.00000)\n",
      "clean (score=0.00000)\n",
      "\n",
      "Evaluation time (1-image): 0.135s\n",
      "\n",
      "not clean (score=1.00000)\n",
      "clean (score=0.00000)\n",
      "\n",
      "Evaluation time (1-image): 0.131s\n",
      "\n",
      "not clean (score=1.00000)\n",
      "clean (score=0.00000)\n",
      "\n",
      "Evaluation time (1-image): 0.135s\n",
      "\n",
      "not clean (score=1.00000)\n",
      "clean (score=0.00000)\n",
      "\n",
      "Evaluation time (1-image): 0.141s\n",
      "\n",
      "not clean (score=1.00000)\n",
      "clean (score=0.00000)\n",
      "\n",
      "Evaluation time (1-image): 0.135s\n",
      "\n",
      "not clean (score=1.00000)\n",
      "clean (score=0.00000)\n",
      "\n",
      "Evaluation time (1-image): 0.135s\n",
      "\n",
      "not clean (score=1.00000)\n",
      "clean (score=0.00000)\n",
      "\n",
      "Evaluation time (1-image): 0.134s\n",
      "\n",
      "not clean (score=1.00000)\n",
      "clean (score=0.00000)\n",
      "\n",
      "Evaluation time (1-image): 0.136s\n",
      "\n",
      "not clean (score=1.00000)\n",
      "clean (score=0.00000)\n",
      "\n",
      "Evaluation time (1-image): 0.133s\n",
      "\n",
      "not clean (score=1.00000)\n",
      "clean (score=0.00000)\n",
      "\n",
      "Evaluation time (1-image): 0.144s\n",
      "\n",
      "not clean (score=1.00000)\n",
      "clean (score=0.00000)\n",
      "\n",
      "Evaluation time (1-image): 0.135s\n",
      "\n",
      "not clean (score=1.00000)\n",
      "clean (score=0.00000)\n",
      "\n",
      "Evaluation time (1-image): 0.135s\n",
      "\n",
      "not clean (score=1.00000)\n",
      "clean (score=0.00000)\n",
      "\n",
      "Evaluation time (1-image): 0.133s\n",
      "\n",
      "not clean (score=1.00000)\n",
      "clean (score=0.00000)\n",
      "\n",
      "Evaluation time (1-image): 0.134s\n",
      "\n",
      "not clean (score=1.00000)\n",
      "clean (score=0.00000)\n",
      "\n",
      "Evaluation time (1-image): 0.145s\n",
      "\n",
      "not clean (score=1.00000)\n",
      "clean (score=0.00000)\n",
      "\n",
      "Evaluation time (1-image): 0.137s\n",
      "\n",
      "not clean (score=1.00000)\n",
      "clean (score=0.00000)\n",
      "\n",
      "Evaluation time (1-image): 0.133s\n",
      "\n",
      "not clean (score=1.00000)\n",
      "clean (score=0.00000)\n",
      "\n",
      "Evaluation time (1-image): 0.132s\n",
      "\n",
      "not clean (score=1.00000)\n",
      "clean (score=0.00000)\n",
      "\n",
      "Evaluation time (1-image): 0.132s\n",
      "\n",
      "not clean (score=1.00000)\n",
      "clean (score=0.00000)\n",
      "\n",
      "Evaluation time (1-image): 0.137s\n",
      "\n",
      "not clean (score=1.00000)\n",
      "clean (score=0.00000)\n",
      "\n",
      "Evaluation time (1-image): 0.130s\n",
      "\n",
      "not clean (score=1.00000)\n",
      "clean (score=0.00000)\n",
      "\n",
      "Evaluation time (1-image): 0.132s\n",
      "\n",
      "not clean (score=1.00000)\n",
      "clean (score=0.00000)\n",
      "\n",
      "Evaluation time (1-image): 0.133s\n",
      "\n",
      "not clean (score=1.00000)\n",
      "clean (score=0.00000)\n",
      "\n",
      "Evaluation time (1-image): 0.130s\n",
      "\n",
      "not clean (score=1.00000)\n",
      "clean (score=0.00000)\n",
      "Percentage that is not clean 99.97997646746428\n",
      "Time Taken:  0.2996039390563965\n",
      "Done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Garbage Detected'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(\"1 - Made with Clipchamp.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c15897-bd05-4353-be9d-3b2026d0bd4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Intel® oneAPI 2023.0)",
   "language": "python",
   "name": "c009-intel_distribution_of_python_3_oneapi-beta05-python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
